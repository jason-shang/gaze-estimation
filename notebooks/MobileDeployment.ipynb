{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15f86d2d",
   "metadata": {},
   "source": [
    "## Exporting Model to TorchScript for Inference at Mobile Runtime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad7bdce4",
   "metadata": {},
   "source": [
    "### Dependencies & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edb6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221d4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../src/pred/')\n",
    "sys.path.insert(1, '../src/datasets')\n",
    "\n",
    "from model import gazetrack_model\n",
    "from gazetrack_data import gazetrack_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84facae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for gazetrack_model:\n\tsize mismatch for lmModel.model.0.weight: copying a param with shape torch.Size([128, 8]) from checkpoint, the shape in current model is torch.Size([128, 11]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(dev)\n\u001b[1;32m      9\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m../checkpoints/GoogleCheckpoint_GoogleSplit.ckpt\u001b[39m\u001b[39m\"\u001b[39m, map_location\u001b[39m=\u001b[39mdev)[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(weights)\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mto(dev)\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Documents/School/Duke/2022-2023/BME493/GazeTrack/gaze-track-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for gazetrack_model:\n\tsize mismatch for lmModel.model.0.weight: copying a param with shape torch.Size([128, 8]) from checkpoint, the shape in current model is torch.Size([128, 11])."
     ]
    }
   ],
   "source": [
    "model = gazetrack_model()\n",
    "if(torch.cuda.is_available()):\n",
    "    dev = torch.device('cuda:0')\n",
    "else:\n",
    "    dev = torch.device('cpu')\n",
    "\n",
    "print(dev)\n",
    "    \n",
    "weights = torch.load(\"../checkpoints/GoogleCheckpoint_GoogleSplit.ckpt\", map_location=dev)['state_dict']\n",
    "model.load_state_dict(weights)\n",
    "model.to(dev)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "339c0201",
   "metadata": {},
   "source": [
    "## Fuse Layers\n",
    "https://pytorch.org/docs/stable/generated/torch.quantization.fuse_modules.html\n",
    "\n",
    "conv, bn\n",
    "conv, bn, relu\n",
    "conv, relu\n",
    "linear, relu\n",
    "bn, relu\n",
    "\n",
    "Don't know if fusing is achievable here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9249ef86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'gazetrack_model' object has no attribute 'conv_bn_relu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m modules_to_fuse \u001b[39m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m modules_to_fuse\u001b[39m.\u001b[39mappend([\u001b[39m'\u001b[39m\u001b[39mconv_bn_relu.conv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mconv_bn_relu.bn\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39;49mquantization\u001b[39m.\u001b[39;49mfuse_modules(model, modules_to_fuse, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/Documents/School/Duke/2022-2023/BME493/GazeTrack/gaze-track-venv/lib/python3.9/site-packages/torch/ao/quantization/fuse_modules.py:158\u001b[0m, in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfuse_modules\u001b[39m(model, modules_to_fuse, inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fuser_func\u001b[39m=\u001b[39mfuse_known_modules, fuse_custom_config_dict\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Fuses a list of modules into a single module\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    Fuses only the following sequence of modules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m _fuse_modules(\n\u001b[1;32m    159\u001b[0m         model,\n\u001b[1;32m    160\u001b[0m         modules_to_fuse,\n\u001b[1;32m    161\u001b[0m         is_qat\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    162\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m    163\u001b[0m         fuser_func\u001b[39m=\u001b[39;49mfuser_func,\n\u001b[1;32m    164\u001b[0m         fuse_custom_config_dict\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/School/Duke/2022-2023/BME493/GazeTrack/gaze-track-venv/lib/python3.9/site-packages/torch/ao/quantization/fuse_modules.py:100\u001b[0m, in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[39m# Handle case of modules_to_fuse being a list of lists\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mfor\u001b[39;00m module_list \u001b[39min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m--> 100\u001b[0m         _fuse_modules_helper(model, module_list, is_qat, fuser_func, fuse_custom_config_dict)\n\u001b[1;32m    101\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/School/Duke/2022-2023/BME493/GazeTrack/gaze-track-venv/lib/python3.9/site-packages/torch/ao/quantization/fuse_modules.py:81\u001b[0m, in \u001b[0;36m_fuse_modules_helper\u001b[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     79\u001b[0m mod_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m---> 81\u001b[0m     mod_list\u001b[39m.\u001b[39mappend(_get_module(model, item))\n\u001b[1;32m     83\u001b[0m \u001b[39m# Fuse list of modules\u001b[39;00m\n\u001b[1;32m     84\u001b[0m new_mod_list \u001b[39m=\u001b[39m fuser_func(mod_list, is_qat, additional_fuser_method_mapping)\n",
      "File \u001b[0;32m~/Documents/School/Duke/2022-2023/BME493/GazeTrack/gaze-track-venv/lib/python3.9/site-packages/torch/ao/quantization/fuse_modules.py:25\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(model, submodule_key)\u001b[0m\n\u001b[1;32m     23\u001b[0m cur_mod \u001b[39m=\u001b[39m model\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m tokens:\n\u001b[0;32m---> 25\u001b[0m     cur_mod \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(cur_mod, s)\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m cur_mod\n",
      "File \u001b[0;32m~/Documents/School/Duke/2022-2023/BME493/GazeTrack/gaze-track-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'gazetrack_model' object has no attribute 'conv_bn_relu'"
     ]
    }
   ],
   "source": [
    "modules_to_fuse = []\n",
    "modules_to_fuse.append(['conv_bn_relu.conv', 'conv_bn_relu.bn'])\n",
    "torch.quantization.fuse_modules(model, modules_to_fuse, inplace=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f87f2b",
   "metadata": {},
   "source": [
    "## Quantize\n",
    "\n",
    "Static post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4abae155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1135: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "\n",
    "torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "# use data set to calibrate quantized weights\n",
    "def calibrate(model, calibration_data): \n",
    "    return\n",
    "\n",
    "calibrate(model, [])\n",
    "\n",
    "model = torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f6c2590",
   "metadata": {},
   "source": [
    "## Save TorchScript Model for Inference at Mobile Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5a6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "torchscript_model = torch.jit.script(model)\n",
    "\n",
    "torchscript_model_optimized = optimize_for_mobile(torchscript_model)\n",
    "\n",
    "torch.jit.save(torchscript_model_optimized, 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaze-track-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
