{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edb6b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69626ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eye_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(eye_model, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32, momentum=0.9),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.02),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64, momentum=0.9),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.02),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(128, momentum=0.9),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.02),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a87f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class landmark_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(landmark_model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(8, 128),\n",
    "            nn.BatchNorm1d(128, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.BatchNorm1d(16, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.BatchNorm1d(16, momentum=0.9),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19a0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gazetrack_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(gazetrack_model, self).__init__()        \n",
    "        self.eye_model = eye_model()\n",
    "#         self.eye_model = torch.quantization.fuse_modules(self.eye_model, \n",
    "#                                                          [['model.0', 'model.1'],\n",
    "#                                                           ['model.5', 'model.6'],\n",
    "#                                                           ['model.10', 'model.11']])\n",
    "        self.lmModel = landmark_model()\n",
    "        self.combined_model = nn.Sequential(nn.Linear(512+512+16, 8),\n",
    "                                            nn.BatchNorm1d(8, momentum=0.9),\n",
    "                                            nn.Dropout(0.12),\n",
    "                                            nn.ReLU(inplace = True),\n",
    "                                            nn.Linear(8, 4),\n",
    "                                            nn.BatchNorm1d(4, momentum=0.9),\n",
    "                                            nn.ReLU(inplace = True),\n",
    "                                            nn.Linear(4, 2),)\n",
    "\n",
    "    def forward(self, leftEye, rightEye, lms):\n",
    "        l_eye_feat = torch.flatten(self.eye_model(leftEye), 1)\n",
    "        r_eye_feat = torch.flatten(self.eye_model(rightEye), 1)\n",
    "        \n",
    "        lm_feat = self.lmModel(lms)\n",
    "        \n",
    "        combined_feat = torch.cat((l_eye_feat, r_eye_feat, lm_feat), 1)\n",
    "        out = self.combined_model(combined_feat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84facae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/GoogleCheckpoint_MITSplit.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     dev \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(dev)\n\u001b[0;32m----> 9\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mcheckpoints/GoogleCheckpoint_MITSplit.ckpt\u001b[39;49m\u001b[39m\"\u001b[39;49m, map_location\u001b[39m=\u001b[39;49mdev)[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(weights)\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mto(dev)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoints/GoogleCheckpoint_MITSplit.ckpt'"
     ]
    }
   ],
   "source": [
    "model = gazetrack_model()\n",
    "if(torch.cuda.is_available()):\n",
    "    dev = torch.device('cuda:0')\n",
    "else:\n",
    "    dev = torch.device('cpu')\n",
    "\n",
    "print(dev)\n",
    "    \n",
    "weights = torch.load(\"checkpoints/GoogleCheckpoint_GoogleSplit.ckpt\", map_location=dev)['state_dict']\n",
    "model.load_state_dict(weights)\n",
    "model.to(dev)\n",
    "model.eval()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c0201",
   "metadata": {},
   "source": [
    "## Fuse Layers\n",
    "https://pytorch.org/docs/stable/generated/torch.quantization.fuse_modules.html\n",
    "\n",
    "conv, bn\n",
    "conv, bn, relu\n",
    "conv, relu\n",
    "linear, relu\n",
    "bn, relu\n",
    "\n",
    "Don't know if fusing is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9249ef86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'gazetrack_model' object has no attribute 'conv_bn_relu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# modules_to_fuse.append(['eye_model.0', 'eye_model.1', 'eye_model.2'])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# modules_to_fuse.append(['eye_model.5', 'eye_model.6', 'eye_model.7'])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# modules_to_fuse.append(['eye_model.10', 'eye_model.11', 'eye_model.12'])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# modules_to_fuse.append(['combined_model.5', 'combined_model.6'])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m modules_to_fuse\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_bn_relu.conv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv_bn_relu.bn\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuse_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules_to_fuse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:151\u001b[0m, in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfuse_modules\u001b[39m(model, modules_to_fuse, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fuser_func\u001b[38;5;241m=\u001b[39mfuse_known_modules, fuse_custom_config_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fuses a list of modules into a single module\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    Fuses only the following sequence of modules:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fuse_modules\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodules_to_fuse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_qat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuser_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuse_known_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuse_custom_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:94\u001b[0m, in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, is_qat, inplace, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# Handle case of modules_to_fuse being a list of lists\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module_list \u001b[38;5;129;01min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m---> 94\u001b[0m         \u001b[43m_fuse_modules_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_qat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuser_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuse_custom_config_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:75\u001b[0m, in \u001b[0;36m_fuse_modules_helper\u001b[0;34m(model, modules_to_fuse, is_qat, fuser_func, fuse_custom_config_dict)\u001b[0m\n\u001b[1;32m     73\u001b[0m mod_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m modules_to_fuse:\n\u001b[0;32m---> 75\u001b[0m     mod_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Fuse list of modules\u001b[39;00m\n\u001b[1;32m     78\u001b[0m new_mod_list \u001b[38;5;241m=\u001b[39m fuser_func(mod_list, is_qat, additional_fuser_method_mapping)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/ao/quantization/fuse_modules.py:19\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(model, submodule_key)\u001b[0m\n\u001b[1;32m     17\u001b[0m cur_mod \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m---> 19\u001b[0m     cur_mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcur_mod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cur_mod\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'gazetrack_model' object has no attribute 'conv_bn_relu'"
     ]
    }
   ],
   "source": [
    "modules_to_fuse = []\n",
    "# modules_to_fuse.append(['eye_model.0', 'eye_model.1', 'eye_model.2'])\n",
    "# modules_to_fuse.append(['eye_model.5', 'eye_model.6', 'eye_model.7'])\n",
    "# modules_to_fuse.append(['eye_model.10', 'eye_model.11', 'eye_model.12'])\n",
    "# modules_to_fuse.append(['eye_model.0', 'eye_model.1', 'eye_model.2'])\n",
    "\n",
    "# modules_to_fuse.append(['lmModel.0', 'lmModel.1', 'lmModel.2'])\n",
    "# modules_to_fuse.append(['lmModel.3', 'lmModel.4', 'lmModel.5'])\n",
    "# modules_to_fuse.append(['lmModel.6', 'lmModel.7', 'lmModel.8'])\n",
    "\n",
    "# modules_to_fuse.append(['combined_model.5', 'combined_model.6'])\n",
    "modules_to_fuse.append(['conv_bn_relu.conv', 'conv_bn_relu.bn'])\n",
    "torch.quantization.fuse_modules(model, modules_to_fuse, inplace=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f87f2b",
   "metadata": {},
   "source": [
    "## Quantize\n",
    "\n",
    "Static post-training quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4abae155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jason/opt/anaconda3/envs/gaze-track/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1135: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "\n",
    "torch.quantization.prepare(model, inplace=True)\n",
    "\n",
    "# use data set to calibrate quantized weights\n",
    "def calibrate(model, calibration_data): \n",
    "    return\n",
    "\n",
    "calibrate(model, [])\n",
    "\n",
    "model = torch.quantization.convert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c2590",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5a6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "torchscript_model = torch.jit.script(model)\n",
    "\n",
    "torchscript_model_optimized = optimize_for_mobile(torchscript_model)\n",
    "\n",
    "torch.jit.save(torchscript_model_optimized, 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaze-track",
   "language": "python",
   "name": "gaze-track"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
